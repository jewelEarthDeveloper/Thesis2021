\section{Research Method}
\label{section:Research_Method}

To answer the research questions from section \ref{section:Research_Questions}, we pursued three approaches.

Our chosen path to answering RQ 1, ``What is the current state of language workbenches supporting projectional editing?'', was to conduct a systematic literature review (SLR).
The SLR aims to answer this question by interrogating current research with the sub questions, ``Is there any current research in the area of projectional editing?'',  ``Which tools are currently being used for research?'', and ``What is the sentiment in papers currently discussing projectional editing?''.
We describe how we went about this in section \ref{section:slr_method}. 

This showed that whilst still niche, projectional editing is maturing, with one successful language workbench dominating the commercialisation of this field.

We attacked RQ 2, ``Which projections can we create to help developers get appropriate feedback about rules?'', by implementing the Drools language using the MPS language workbench, and creating projections on top of this.
This action design research (ADR) approach is described in detail in section \ref{section:adr_method}.

The outcome of this research were a number of projections that we felt would be able to improve the understanding of larger collections of Drools rules.

Finally, we tackled RQ 3, ``Do projections of Drools business rules lead to greater understanding of those rules?'', with a survey.
We presented our findings in answering RQ2 to experienced industrial and academic Drools users, as laid out in in section \ref{section:survey_method}.
We compared some of our projections with textual projections similar to the code they were used to.

The survey showed that whilst there was interest in the approach and that some projections were more understandable than others, textual presentations, at least for this population, were still considered easier to understand.